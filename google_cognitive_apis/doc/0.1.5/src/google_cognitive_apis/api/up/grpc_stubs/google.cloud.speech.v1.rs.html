<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `src\api\../grpc_stubs/google.cloud.speech.v1.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>google.cloud.speech.v1.rs - source</title><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../SourceSerif4-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../FiraSans-Regular.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../FiraSans-Medium.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../SourceCodePro-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../SourceSerif4-Bold.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../SourceCodePro-Semibold.ttf.woff2"><link rel="stylesheet" href="../../../../../normalize.css"><link rel="stylesheet" href="../../../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" href="../../../../../ayu.css" disabled><link rel="stylesheet" href="../../../../../dark.css" disabled><link rel="stylesheet" href="../../../../../light.css" id="themeStyle"><script id="default-settings" ></script><script src="../../../../../storage.js"></script><script defer src="../../../../../source-script.js"></script><script defer src="../../../../../source-files.js"></script><script defer src="../../../../../main.js"></script><noscript><link rel="stylesheet" href="../../../../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../../../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../../../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../../../../favicon.svg"></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle">&#9776;</button><a class="sidebar-logo" href="../../../../../google_cognitive_apis/index.html"><div class="logo-container"><img class="rust-logo" src="../../../../../rust-logo.svg" alt="logo"></div></a><h2 class="location"></h2></nav><nav class="sidebar"><a class="sidebar-logo" href="../../../../../google_cognitive_apis/index.html"><div class="logo-container"><img class="rust-logo" src="../../../../../rust-logo.svg" alt="logo"></div></a></nav><main><div class="width-limiter"><div class="sub-container"><a class="sub-logo-container" href="../../../../../google_cognitive_apis/index.html"><img class="rust-logo" src="../../../../../rust-logo.svg" alt="logo"></a><nav class="sub"><form class="search-form"><div class="search-container"><span></span><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"><div id="help-button" title="help" tabindex="-1"><button type="button">?</button></div><div id="settings-menu" tabindex="-1"><a href="../../../../../settings.html" title="settings"><img width="22" height="22" alt="Change settings" src="../../../../../wheel.svg"></a></div></div></form></nav></div><section id="main-content" class="content"><div class="example-wrap"><pre class="line-numbers"><span id="1">1</span>
<span id="2">2</span>
<span id="3">3</span>
<span id="4">4</span>
<span id="5">5</span>
<span id="6">6</span>
<span id="7">7</span>
<span id="8">8</span>
<span id="9">9</span>
<span id="10">10</span>
<span id="11">11</span>
<span id="12">12</span>
<span id="13">13</span>
<span id="14">14</span>
<span id="15">15</span>
<span id="16">16</span>
<span id="17">17</span>
<span id="18">18</span>
<span id="19">19</span>
<span id="20">20</span>
<span id="21">21</span>
<span id="22">22</span>
<span id="23">23</span>
<span id="24">24</span>
<span id="25">25</span>
<span id="26">26</span>
<span id="27">27</span>
<span id="28">28</span>
<span id="29">29</span>
<span id="30">30</span>
<span id="31">31</span>
<span id="32">32</span>
<span id="33">33</span>
<span id="34">34</span>
<span id="35">35</span>
<span id="36">36</span>
<span id="37">37</span>
<span id="38">38</span>
<span id="39">39</span>
<span id="40">40</span>
<span id="41">41</span>
<span id="42">42</span>
<span id="43">43</span>
<span id="44">44</span>
<span id="45">45</span>
<span id="46">46</span>
<span id="47">47</span>
<span id="48">48</span>
<span id="49">49</span>
<span id="50">50</span>
<span id="51">51</span>
<span id="52">52</span>
<span id="53">53</span>
<span id="54">54</span>
<span id="55">55</span>
<span id="56">56</span>
<span id="57">57</span>
<span id="58">58</span>
<span id="59">59</span>
<span id="60">60</span>
<span id="61">61</span>
<span id="62">62</span>
<span id="63">63</span>
<span id="64">64</span>
<span id="65">65</span>
<span id="66">66</span>
<span id="67">67</span>
<span id="68">68</span>
<span id="69">69</span>
<span id="70">70</span>
<span id="71">71</span>
<span id="72">72</span>
<span id="73">73</span>
<span id="74">74</span>
<span id="75">75</span>
<span id="76">76</span>
<span id="77">77</span>
<span id="78">78</span>
<span id="79">79</span>
<span id="80">80</span>
<span id="81">81</span>
<span id="82">82</span>
<span id="83">83</span>
<span id="84">84</span>
<span id="85">85</span>
<span id="86">86</span>
<span id="87">87</span>
<span id="88">88</span>
<span id="89">89</span>
<span id="90">90</span>
<span id="91">91</span>
<span id="92">92</span>
<span id="93">93</span>
<span id="94">94</span>
<span id="95">95</span>
<span id="96">96</span>
<span id="97">97</span>
<span id="98">98</span>
<span id="99">99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
<span id="326">326</span>
<span id="327">327</span>
<span id="328">328</span>
<span id="329">329</span>
<span id="330">330</span>
<span id="331">331</span>
<span id="332">332</span>
<span id="333">333</span>
<span id="334">334</span>
<span id="335">335</span>
<span id="336">336</span>
<span id="337">337</span>
<span id="338">338</span>
<span id="339">339</span>
<span id="340">340</span>
<span id="341">341</span>
<span id="342">342</span>
<span id="343">343</span>
<span id="344">344</span>
<span id="345">345</span>
<span id="346">346</span>
<span id="347">347</span>
<span id="348">348</span>
<span id="349">349</span>
<span id="350">350</span>
<span id="351">351</span>
<span id="352">352</span>
<span id="353">353</span>
<span id="354">354</span>
<span id="355">355</span>
<span id="356">356</span>
<span id="357">357</span>
<span id="358">358</span>
<span id="359">359</span>
<span id="360">360</span>
<span id="361">361</span>
<span id="362">362</span>
<span id="363">363</span>
<span id="364">364</span>
<span id="365">365</span>
<span id="366">366</span>
<span id="367">367</span>
<span id="368">368</span>
<span id="369">369</span>
<span id="370">370</span>
<span id="371">371</span>
<span id="372">372</span>
<span id="373">373</span>
<span id="374">374</span>
<span id="375">375</span>
<span id="376">376</span>
<span id="377">377</span>
<span id="378">378</span>
<span id="379">379</span>
<span id="380">380</span>
<span id="381">381</span>
<span id="382">382</span>
<span id="383">383</span>
<span id="384">384</span>
<span id="385">385</span>
<span id="386">386</span>
<span id="387">387</span>
<span id="388">388</span>
<span id="389">389</span>
<span id="390">390</span>
<span id="391">391</span>
<span id="392">392</span>
<span id="393">393</span>
<span id="394">394</span>
<span id="395">395</span>
<span id="396">396</span>
<span id="397">397</span>
<span id="398">398</span>
<span id="399">399</span>
<span id="400">400</span>
<span id="401">401</span>
<span id="402">402</span>
<span id="403">403</span>
<span id="404">404</span>
<span id="405">405</span>
<span id="406">406</span>
<span id="407">407</span>
<span id="408">408</span>
<span id="409">409</span>
<span id="410">410</span>
<span id="411">411</span>
<span id="412">412</span>
<span id="413">413</span>
<span id="414">414</span>
<span id="415">415</span>
<span id="416">416</span>
<span id="417">417</span>
<span id="418">418</span>
<span id="419">419</span>
<span id="420">420</span>
<span id="421">421</span>
<span id="422">422</span>
<span id="423">423</span>
<span id="424">424</span>
<span id="425">425</span>
<span id="426">426</span>
<span id="427">427</span>
<span id="428">428</span>
<span id="429">429</span>
<span id="430">430</span>
<span id="431">431</span>
<span id="432">432</span>
<span id="433">433</span>
<span id="434">434</span>
<span id="435">435</span>
<span id="436">436</span>
<span id="437">437</span>
<span id="438">438</span>
<span id="439">439</span>
<span id="440">440</span>
<span id="441">441</span>
<span id="442">442</span>
<span id="443">443</span>
<span id="444">444</span>
<span id="445">445</span>
<span id="446">446</span>
<span id="447">447</span>
<span id="448">448</span>
<span id="449">449</span>
<span id="450">450</span>
<span id="451">451</span>
<span id="452">452</span>
<span id="453">453</span>
<span id="454">454</span>
<span id="455">455</span>
<span id="456">456</span>
<span id="457">457</span>
<span id="458">458</span>
<span id="459">459</span>
<span id="460">460</span>
<span id="461">461</span>
<span id="462">462</span>
<span id="463">463</span>
<span id="464">464</span>
<span id="465">465</span>
<span id="466">466</span>
<span id="467">467</span>
<span id="468">468</span>
<span id="469">469</span>
<span id="470">470</span>
<span id="471">471</span>
<span id="472">472</span>
<span id="473">473</span>
<span id="474">474</span>
<span id="475">475</span>
<span id="476">476</span>
<span id="477">477</span>
<span id="478">478</span>
<span id="479">479</span>
<span id="480">480</span>
<span id="481">481</span>
<span id="482">482</span>
<span id="483">483</span>
<span id="484">484</span>
<span id="485">485</span>
<span id="486">486</span>
<span id="487">487</span>
<span id="488">488</span>
<span id="489">489</span>
<span id="490">490</span>
<span id="491">491</span>
<span id="492">492</span>
<span id="493">493</span>
<span id="494">494</span>
<span id="495">495</span>
<span id="496">496</span>
<span id="497">497</span>
<span id="498">498</span>
<span id="499">499</span>
<span id="500">500</span>
<span id="501">501</span>
<span id="502">502</span>
<span id="503">503</span>
<span id="504">504</span>
<span id="505">505</span>
<span id="506">506</span>
<span id="507">507</span>
<span id="508">508</span>
<span id="509">509</span>
<span id="510">510</span>
<span id="511">511</span>
<span id="512">512</span>
<span id="513">513</span>
<span id="514">514</span>
<span id="515">515</span>
<span id="516">516</span>
<span id="517">517</span>
<span id="518">518</span>
<span id="519">519</span>
<span id="520">520</span>
<span id="521">521</span>
<span id="522">522</span>
<span id="523">523</span>
<span id="524">524</span>
<span id="525">525</span>
<span id="526">526</span>
<span id="527">527</span>
<span id="528">528</span>
<span id="529">529</span>
<span id="530">530</span>
<span id="531">531</span>
<span id="532">532</span>
<span id="533">533</span>
<span id="534">534</span>
<span id="535">535</span>
<span id="536">536</span>
<span id="537">537</span>
<span id="538">538</span>
<span id="539">539</span>
<span id="540">540</span>
<span id="541">541</span>
<span id="542">542</span>
<span id="543">543</span>
<span id="544">544</span>
<span id="545">545</span>
<span id="546">546</span>
<span id="547">547</span>
<span id="548">548</span>
<span id="549">549</span>
<span id="550">550</span>
<span id="551">551</span>
<span id="552">552</span>
<span id="553">553</span>
<span id="554">554</span>
<span id="555">555</span>
<span id="556">556</span>
<span id="557">557</span>
<span id="558">558</span>
<span id="559">559</span>
<span id="560">560</span>
<span id="561">561</span>
<span id="562">562</span>
<span id="563">563</span>
<span id="564">564</span>
<span id="565">565</span>
<span id="566">566</span>
<span id="567">567</span>
<span id="568">568</span>
<span id="569">569</span>
<span id="570">570</span>
<span id="571">571</span>
<span id="572">572</span>
<span id="573">573</span>
<span id="574">574</span>
<span id="575">575</span>
<span id="576">576</span>
<span id="577">577</span>
<span id="578">578</span>
<span id="579">579</span>
<span id="580">580</span>
<span id="581">581</span>
<span id="582">582</span>
<span id="583">583</span>
<span id="584">584</span>
<span id="585">585</span>
<span id="586">586</span>
<span id="587">587</span>
<span id="588">588</span>
<span id="589">589</span>
<span id="590">590</span>
<span id="591">591</span>
<span id="592">592</span>
<span id="593">593</span>
<span id="594">594</span>
<span id="595">595</span>
<span id="596">596</span>
<span id="597">597</span>
<span id="598">598</span>
<span id="599">599</span>
<span id="600">600</span>
<span id="601">601</span>
<span id="602">602</span>
<span id="603">603</span>
<span id="604">604</span>
<span id="605">605</span>
<span id="606">606</span>
<span id="607">607</span>
<span id="608">608</span>
<span id="609">609</span>
<span id="610">610</span>
<span id="611">611</span>
<span id="612">612</span>
<span id="613">613</span>
<span id="614">614</span>
<span id="615">615</span>
<span id="616">616</span>
<span id="617">617</span>
<span id="618">618</span>
<span id="619">619</span>
<span id="620">620</span>
<span id="621">621</span>
<span id="622">622</span>
<span id="623">623</span>
<span id="624">624</span>
<span id="625">625</span>
<span id="626">626</span>
<span id="627">627</span>
<span id="628">628</span>
<span id="629">629</span>
<span id="630">630</span>
<span id="631">631</span>
<span id="632">632</span>
<span id="633">633</span>
<span id="634">634</span>
<span id="635">635</span>
<span id="636">636</span>
<span id="637">637</span>
<span id="638">638</span>
<span id="639">639</span>
<span id="640">640</span>
<span id="641">641</span>
<span id="642">642</span>
<span id="643">643</span>
<span id="644">644</span>
<span id="645">645</span>
<span id="646">646</span>
<span id="647">647</span>
<span id="648">648</span>
<span id="649">649</span>
<span id="650">650</span>
<span id="651">651</span>
<span id="652">652</span>
<span id="653">653</span>
<span id="654">654</span>
<span id="655">655</span>
<span id="656">656</span>
<span id="657">657</span>
<span id="658">658</span>
<span id="659">659</span>
<span id="660">660</span>
<span id="661">661</span>
<span id="662">662</span>
<span id="663">663</span>
<span id="664">664</span>
<span id="665">665</span>
<span id="666">666</span>
<span id="667">667</span>
<span id="668">668</span>
<span id="669">669</span>
<span id="670">670</span>
<span id="671">671</span>
<span id="672">672</span>
<span id="673">673</span>
<span id="674">674</span>
<span id="675">675</span>
<span id="676">676</span>
<span id="677">677</span>
<span id="678">678</span>
<span id="679">679</span>
<span id="680">680</span>
<span id="681">681</span>
<span id="682">682</span>
<span id="683">683</span>
<span id="684">684</span>
<span id="685">685</span>
<span id="686">686</span>
<span id="687">687</span>
<span id="688">688</span>
<span id="689">689</span>
<span id="690">690</span>
<span id="691">691</span>
<span id="692">692</span>
<span id="693">693</span>
<span id="694">694</span>
<span id="695">695</span>
<span id="696">696</span>
<span id="697">697</span>
<span id="698">698</span>
<span id="699">699</span>
<span id="700">700</span>
<span id="701">701</span>
<span id="702">702</span>
<span id="703">703</span>
<span id="704">704</span>
<span id="705">705</span>
<span id="706">706</span>
<span id="707">707</span>
<span id="708">708</span>
<span id="709">709</span>
<span id="710">710</span>
<span id="711">711</span>
<span id="712">712</span>
<span id="713">713</span>
<span id="714">714</span>
<span id="715">715</span>
<span id="716">716</span>
<span id="717">717</span>
<span id="718">718</span>
<span id="719">719</span>
<span id="720">720</span>
<span id="721">721</span>
<span id="722">722</span>
<span id="723">723</span>
<span id="724">724</span>
<span id="725">725</span>
<span id="726">726</span>
<span id="727">727</span>
<span id="728">728</span>
<span id="729">729</span>
<span id="730">730</span>
<span id="731">731</span>
<span id="732">732</span>
<span id="733">733</span>
<span id="734">734</span>
<span id="735">735</span>
<span id="736">736</span>
<span id="737">737</span>
<span id="738">738</span>
<span id="739">739</span>
<span id="740">740</span>
<span id="741">741</span>
<span id="742">742</span>
<span id="743">743</span>
<span id="744">744</span>
<span id="745">745</span>
<span id="746">746</span>
<span id="747">747</span>
<span id="748">748</span>
<span id="749">749</span>
<span id="750">750</span>
<span id="751">751</span>
<span id="752">752</span>
<span id="753">753</span>
<span id="754">754</span>
<span id="755">755</span>
<span id="756">756</span>
<span id="757">757</span>
<span id="758">758</span>
<span id="759">759</span>
<span id="760">760</span>
<span id="761">761</span>
<span id="762">762</span>
<span id="763">763</span>
<span id="764">764</span>
<span id="765">765</span>
<span id="766">766</span>
<span id="767">767</span>
<span id="768">768</span>
<span id="769">769</span>
<span id="770">770</span>
<span id="771">771</span>
<span id="772">772</span>
<span id="773">773</span>
<span id="774">774</span>
<span id="775">775</span>
<span id="776">776</span>
<span id="777">777</span>
<span id="778">778</span>
<span id="779">779</span>
<span id="780">780</span>
<span id="781">781</span>
<span id="782">782</span>
<span id="783">783</span>
<span id="784">784</span>
<span id="785">785</span>
<span id="786">786</span>
<span id="787">787</span>
<span id="788">788</span>
<span id="789">789</span>
<span id="790">790</span>
<span id="791">791</span>
<span id="792">792</span>
<span id="793">793</span>
<span id="794">794</span>
<span id="795">795</span>
<span id="796">796</span>
<span id="797">797</span>
<span id="798">798</span>
<span id="799">799</span>
<span id="800">800</span>
<span id="801">801</span>
<span id="802">802</span>
<span id="803">803</span>
<span id="804">804</span>
<span id="805">805</span>
<span id="806">806</span>
<span id="807">807</span>
<span id="808">808</span>
<span id="809">809</span>
<span id="810">810</span>
<span id="811">811</span>
<span id="812">812</span>
<span id="813">813</span>
<span id="814">814</span>
<span id="815">815</span>
<span id="816">816</span>
<span id="817">817</span>
<span id="818">818</span>
<span id="819">819</span>
<span id="820">820</span>
</pre><pre class="rust"><code><span class="doccomment">/// The top-level message sent by the client for the `Recognize` method.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>RecognizeRequest {
    <span class="doccomment">/// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>config: ::core::option::Option&lt;RecognitionConfig&gt;,
    <span class="doccomment">/// Required. The audio data to be recognized.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>audio: ::core::option::Option&lt;RecognitionAudio&gt;,
}
<span class="doccomment">/// The top-level message sent by the client for the `LongRunningRecognize`
/// method.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>LongRunningRecognizeRequest {
    <span class="doccomment">/// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>config: ::core::option::Option&lt;RecognitionConfig&gt;,
    <span class="doccomment">/// Required. The audio data to be recognized.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>audio: ::core::option::Option&lt;RecognitionAudio&gt;,
}
<span class="doccomment">/// The top-level message sent by the client for the `StreamingRecognize` method.
/// Multiple `StreamingRecognizeRequest` messages are sent. The first message
/// must contain a `streaming_config` message and must not contain
/// `audio_content`. All subsequent messages must contain `audio_content` and
/// must not contain a `streaming_config` message.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>StreamingRecognizeRequest {
    <span class="doccomment">/// The streaming request, which is either a streaming config or audio content.
    </span><span class="attribute">#[prost(oneof = <span class="string">&quot;streaming_recognize_request::StreamingRequest&quot;</span>, tags = <span class="string">&quot;1, 2&quot;</span>)]
    </span><span class="kw">pub </span>streaming_request: ::core::option::Option&lt;streaming_recognize_request::StreamingRequest&gt;,
}
<span class="doccomment">/// Nested message and enum types in `StreamingRecognizeRequest`.
</span><span class="kw">pub mod </span>streaming_recognize_request {
    <span class="doccomment">/// The streaming request, which is either a streaming config or audio content.
    </span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Oneof)]
    </span><span class="kw">pub enum </span>StreamingRequest {
        <span class="doccomment">/// Provides information to the recognizer that specifies how to process the
        /// request. The first `StreamingRecognizeRequest` message must contain a
        /// `streaming_config`  message.
        </span><span class="attribute">#[prost(message, tag = <span class="string">&quot;1&quot;</span>)]
        </span>StreamingConfig(<span class="kw">super</span>::StreamingRecognitionConfig),
        <span class="doccomment">/// The audio data to be recognized. Sequential chunks of audio data are sent
        /// in sequential `StreamingRecognizeRequest` messages. The first
        /// `StreamingRecognizeRequest` message must not contain `audio_content` data
        /// and all subsequent `StreamingRecognizeRequest` messages must contain
        /// `audio_content` data. The audio bytes must be encoded as specified in
        /// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
        /// pure binary representation (not base64). See
        /// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
        </span><span class="attribute">#[prost(bytes, tag = <span class="string">&quot;2&quot;</span>)]
        </span>AudioContent(::prost::alloc::vec::Vec&lt;u8&gt;),
    }
}
<span class="doccomment">/// Provides information to the recognizer that specifies how to process the
/// request.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>StreamingRecognitionConfig {
    <span class="doccomment">/// Required. Provides information to the recognizer that specifies how to
    /// process the request.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>config: ::core::option::Option&lt;RecognitionConfig&gt;,
    <span class="doccomment">/// If `false` or omitted, the recognizer will perform continuous
    /// recognition (continuing to wait for and process audio even if the user
    /// pauses speaking) until the client closes the input stream (gRPC API) or
    /// until the maximum time limit has been reached. May return multiple
    /// `StreamingRecognitionResult`s with the `is_final` flag set to `true`.
    ///
    /// If `true`, the recognizer will detect a single spoken utterance. When it
    /// detects that the user has paused or stopped speaking, it will return an
    /// `END_OF_SINGLE_UTTERANCE` event and cease recognition. It will return no
    /// more than one `StreamingRecognitionResult` with the `is_final` flag set to
    /// `true`.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>single_utterance: bool,
    <span class="doccomment">/// If `true`, interim results (tentative hypotheses) may be
    /// returned as they become available (these interim results are indicated with
    /// the `is_final=false` flag).
    /// If `false` or omitted, only `is_final=true` result(s) are returned.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>interim_results: bool,
}
<span class="doccomment">/// Provides information to the recognizer that specifies how to process the
/// request.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>RecognitionConfig {
    <span class="doccomment">/// Encoding of audio data sent in all `RecognitionAudio` messages.
    /// This field is optional for `FLAC` and `WAV` audio files and required
    /// for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
    </span><span class="attribute">#[prost(enumeration = <span class="string">&quot;recognition_config::AudioEncoding&quot;</span>, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>encoding: i32,
    <span class="doccomment">/// Sample rate in Hertz of the audio data sent in all
    /// `RecognitionAudio` messages. Valid values are: 8000-48000.
    /// 16000 is optimal. For best results, set the sampling rate of the audio
    /// source to 16000 Hz. If that&#39;s not possible, use the native sample rate of
    /// the audio source (instead of re-sampling).
    /// This field is optional for FLAC and WAV audio files, but is
    /// required for all other audio formats. For details, see [AudioEncoding][google.cloud.speech.v1.RecognitionConfig.AudioEncoding].
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>sample_rate_hertz: i32,
    <span class="doccomment">/// The number of channels in the input audio data.
    /// ONLY set this for MULTI-CHANNEL recognition.
    /// Valid values for LINEAR16 and FLAC are `1`-`8`.
    /// Valid values for OGG_OPUS are &#39;1&#39;-&#39;254&#39;.
    /// Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
    /// If `0` or omitted, defaults to one channel (mono).
    /// Note: We only recognize the first channel by default.
    /// To perform independent recognition on each channel set
    /// `enable_separate_recognition_per_channel` to &#39;true&#39;.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;7&quot;</span>)]
    </span><span class="kw">pub </span>audio_channel_count: i32,
    <span class="doccomment">/// This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
    /// to get each channel recognized separately. The recognition result will
    /// contain a `channel_tag` field to state which channel that result belongs
    /// to. If this is not true, we will only recognize the first channel. The
    /// request is billed cumulatively for all channels recognized:
    /// `audio_channel_count` multiplied by the length of the audio.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;12&quot;</span>)]
    </span><span class="kw">pub </span>enable_separate_recognition_per_channel: bool,
    <span class="doccomment">/// Required. The language of the supplied audio as a
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    /// Example: &quot;en-US&quot;.
    /// See [Language
    /// Support](https://cloud.google.com/speech-to-text/docs/languages) for a list
    /// of the currently supported language codes.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>language_code: ::prost::alloc::string::String,
    <span class="doccomment">/// Maximum number of recognition hypotheses to be returned.
    /// Specifically, the maximum number of `SpeechRecognitionAlternative` messages
    /// within each `SpeechRecognitionResult`.
    /// The server may return fewer than `max_alternatives`.
    /// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
    /// one. If omitted, will return a maximum of one.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;4&quot;</span>)]
    </span><span class="kw">pub </span>max_alternatives: i32,
    <span class="doccomment">/// If set to `true`, the server will attempt to filter out
    /// profanities, replacing all but the initial character in each filtered word
    /// with asterisks, e.g. &quot;f***&quot;. If set to `false` or omitted, profanities
    /// won&#39;t be filtered out.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;5&quot;</span>)]
    </span><span class="kw">pub </span>profanity_filter: bool,
    <span class="doccomment">/// Array of [SpeechContext][google.cloud.speech.v1.SpeechContext].
    /// A means to provide context to assist the speech recognition. For more
    /// information, see
    /// [speech
    /// adaptation](https://cloud.google.com/speech-to-text/docs/context-strength).
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;6&quot;</span>)]
    </span><span class="kw">pub </span>speech_contexts: ::prost::alloc::vec::Vec&lt;SpeechContext&gt;,
    <span class="doccomment">/// If `true`, the top result includes a list of words and
    /// the start and end time offsets (timestamps) for those words. If
    /// `false`, no word-level time offset information is returned. The default is
    /// `false`.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;8&quot;</span>)]
    </span><span class="kw">pub </span>enable_word_time_offsets: bool,
    <span class="doccomment">/// If &#39;true&#39;, adds punctuation to recognition result hypotheses.
    /// This feature is only available in select languages. Setting this for
    /// requests in other languages has no effect at all.
    /// The default &#39;false&#39; value does not add punctuation to result hypotheses.
    /// Note: This is currently offered as an experimental service, complimentary
    /// to all users. In the future this may be exclusively available as a
    /// premium feature.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;11&quot;</span>)]
    </span><span class="kw">pub </span>enable_automatic_punctuation: bool,
    <span class="doccomment">/// Config to enable speaker diarization and set additional
    /// parameters to make diarization better suited for your application.
    /// Note: When this is enabled, we send all the words from the beginning of the
    /// audio for the top alternative in every consecutive STREAMING responses.
    /// This is done in order to improve our speaker tags as our models learn to
    /// identify the speakers in the conversation over time.
    /// For non-streaming requests, the diarization results will be provided only
    /// in the top alternative of the FINAL SpeechRecognitionResult.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;19&quot;</span>)]
    </span><span class="kw">pub </span>diarization_config: ::core::option::Option&lt;SpeakerDiarizationConfig&gt;,
    <span class="doccomment">/// Metadata regarding this request.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;9&quot;</span>)]
    </span><span class="kw">pub </span>metadata: ::core::option::Option&lt;RecognitionMetadata&gt;,
    <span class="doccomment">/// Which model to select for the given request. Select the model
    /// best suited to your domain to get best results. If a model is not
    /// explicitly specified, then we auto-select a model based on the parameters
    /// in the RecognitionConfig.
    /// &lt;table&gt;
    ///   &lt;tr&gt;
    ///     &lt;td&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/td&gt;
    ///     &lt;td&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/td&gt;
    ///   &lt;/tr&gt;
    ///   &lt;tr&gt;
    ///     &lt;td&gt;&lt;code&gt;command_and_search&lt;/code&gt;&lt;/td&gt;
    ///     &lt;td&gt;Best for short queries such as voice commands or voice search.&lt;/td&gt;
    ///   &lt;/tr&gt;
    ///   &lt;tr&gt;
    ///     &lt;td&gt;&lt;code&gt;phone_call&lt;/code&gt;&lt;/td&gt;
    ///     &lt;td&gt;Best for audio that originated from a phone call (typically
    ///     recorded at an 8khz sampling rate).&lt;/td&gt;
    ///   &lt;/tr&gt;
    ///   &lt;tr&gt;
    ///     &lt;td&gt;&lt;code&gt;video&lt;/code&gt;&lt;/td&gt;
    ///     &lt;td&gt;Best for audio that originated from from video or includes multiple
    ///         speakers. Ideally the audio is recorded at a 16khz or greater
    ///         sampling rate. This is a premium model that costs more than the
    ///         standard rate.&lt;/td&gt;
    ///   &lt;/tr&gt;
    ///   &lt;tr&gt;
    ///     &lt;td&gt;&lt;code&gt;default&lt;/code&gt;&lt;/td&gt;
    ///     &lt;td&gt;Best for audio that is not one of the specific audio models.
    ///         For example, long-form audio. Ideally the audio is high-fidelity,
    ///         recorded at a 16khz or greater sampling rate.&lt;/td&gt;
    ///   &lt;/tr&gt;
    /// &lt;/table&gt;
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;13&quot;</span>)]
    </span><span class="kw">pub </span>model: ::prost::alloc::string::String,
    <span class="doccomment">/// Set to true to use an enhanced model for speech recognition.
    /// If `use_enhanced` is set to true and the `model` field is not set, then
    /// an appropriate enhanced model is chosen if an enhanced model exists for
    /// the audio.
    ///
    /// If `use_enhanced` is true and an enhanced version of the specified model
    /// does not exist, then the speech is recognized using the standard version
    /// of the specified model.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;14&quot;</span>)]
    </span><span class="kw">pub </span>use_enhanced: bool,
}
<span class="doccomment">/// Nested message and enum types in `RecognitionConfig`.
</span><span class="kw">pub mod </span>recognition_config {
    <span class="doccomment">/// The encoding of the audio data sent in the request.
    ///
    /// All encodings support only 1 channel (mono) audio, unless the
    /// `audio_channel_count` and `enable_separate_recognition_per_channel` fields
    /// are set.
    ///
    /// For best results, the audio source should be captured and transmitted using
    /// a lossless encoding (`FLAC` or `LINEAR16`). The accuracy of the speech
    /// recognition can be reduced if lossy codecs are used to capture or transmit
    /// audio, particularly if background noise is present. Lossy codecs include
    /// `MULAW`, `AMR`, `AMR_WB`, `OGG_OPUS`, `SPEEX_WITH_HEADER_BYTE`, and `MP3`.
    ///
    /// The `FLAC` and `WAV` audio file formats include a header that describes the
    /// included audio content. You can request recognition for `WAV` files that
    /// contain either `LINEAR16` or `MULAW` encoded audio.
    /// If you send `FLAC` or `WAV` audio file format in
    /// your request, you do not need to specify an `AudioEncoding`; the audio
    /// encoding format is determined from the file header. If you specify
    /// an `AudioEncoding` when you send  send `FLAC` or `WAV` audio, the
    /// encoding configuration must match the encoding described in the audio
    /// header; otherwise the request returns an
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT] error code.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>AudioEncoding {
        <span class="doccomment">/// Not specified.
        </span>EncodingUnspecified = <span class="number">0</span>,
        <span class="doccomment">/// Uncompressed 16-bit signed little-endian samples (Linear PCM).
        </span>Linear16 = <span class="number">1</span>,
        <span class="doccomment">/// `FLAC` (Free Lossless Audio
        /// Codec) is the recommended encoding because it is
        /// lossless--therefore recognition is not compromised--and
        /// requires only about half the bandwidth of `LINEAR16`. `FLAC` stream
        /// encoding supports 16-bit and 24-bit samples, however, not all fields in
        /// `STREAMINFO` are supported.
        </span>Flac = <span class="number">2</span>,
        <span class="doccomment">/// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
        </span>Mulaw = <span class="number">3</span>,
        <span class="doccomment">/// Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.
        </span>Amr = <span class="number">4</span>,
        <span class="doccomment">/// Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.
        </span>AmrWb = <span class="number">5</span>,
        <span class="doccomment">/// Opus encoded audio frames in Ogg container
        /// ([OggOpus](https://wiki.xiph.org/OggOpus)).
        /// `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000, or 48000.
        </span>OggOpus = <span class="number">6</span>,
        <span class="doccomment">/// Although the use of lossy encodings is not recommended, if a very low
        /// bitrate encoding is required, `OGG_OPUS` is highly preferred over
        /// Speex encoding. The [Speex](https://speex.org/)  encoding supported by
        /// Cloud Speech API has a header byte in each block, as in MIME type
        /// `audio/x-speex-with-header-byte`.
        /// It is a variant of the RTP Speex encoding defined in
        /// [RFC 5574](https://tools.ietf.org/html/rfc5574).
        /// The stream is a sequence of blocks, one block per RTP packet. Each block
        /// starts with a byte containing the length of the block, in bytes, followed
        /// by one or more frames of Speex data, padded to an integral number of
        /// bytes (octets) as specified in RFC 5574. In other words, each RTP header
        /// is replaced with a single byte containing the block length. Only Speex
        /// wideband is supported. `sample_rate_hertz` must be 16000.
        </span>SpeexWithHeaderByte = <span class="number">7</span>,
    }
}
<span class="doccomment">/// Config to enable speaker diarization.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>SpeakerDiarizationConfig {
    <span class="doccomment">/// If &#39;true&#39;, enables speaker detection for each recognized word in
    /// the top alternative of the recognition result using a speaker_tag provided
    /// in the WordInfo.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>enable_speaker_diarization: bool,
    <span class="doccomment">/// Minimum number of speakers in the conversation. This range gives you more
    /// flexibility by allowing the system to automatically determine the correct
    /// number of speakers. If not set, the default value is 2.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>min_speaker_count: i32,
    <span class="doccomment">/// Maximum number of speakers in the conversation. This range gives you more
    /// flexibility by allowing the system to automatically determine the correct
    /// number of speakers. If not set, the default value is 6.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>max_speaker_count: i32,
    <span class="doccomment">/// Unused.
    </span><span class="attribute">#[deprecated]
    #[prost(int32, tag = <span class="string">&quot;5&quot;</span>)]
    </span><span class="kw">pub </span>speaker_tag: i32,
}
<span class="doccomment">/// Description of audio data to be recognized.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>RecognitionMetadata {
    <span class="doccomment">/// The use case most closely describing the audio content to be recognized.
    </span><span class="attribute">#[prost(enumeration = <span class="string">&quot;recognition_metadata::InteractionType&quot;</span>, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>interaction_type: i32,
    <span class="doccomment">/// The industry vertical to which this speech recognition request most
    /// closely applies. This is most indicative of the topics contained
    /// in the audio.  Use the 6-digit NAICS code to identify the industry
    /// vertical - see https://www.naics.com/search/.
    </span><span class="attribute">#[prost(uint32, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>industry_naics_code_of_audio: u32,
    <span class="doccomment">/// The audio type that most closely describes the audio being recognized.
    </span><span class="attribute">#[prost(enumeration = <span class="string">&quot;recognition_metadata::MicrophoneDistance&quot;</span>, tag = <span class="string">&quot;4&quot;</span>)]
    </span><span class="kw">pub </span>microphone_distance: i32,
    <span class="doccomment">/// The original media the speech was recorded on.
    </span><span class="attribute">#[prost(enumeration = <span class="string">&quot;recognition_metadata::OriginalMediaType&quot;</span>, tag = <span class="string">&quot;5&quot;</span>)]
    </span><span class="kw">pub </span>original_media_type: i32,
    <span class="doccomment">/// The type of device the speech was recorded with.
    </span><span class="attribute">#[prost(enumeration = <span class="string">&quot;recognition_metadata::RecordingDeviceType&quot;</span>, tag = <span class="string">&quot;6&quot;</span>)]
    </span><span class="kw">pub </span>recording_device_type: i32,
    <span class="doccomment">/// The device used to make the recording.  Examples &#39;Nexus 5X&#39; or
    /// &#39;Polycom SoundStation IP 6000&#39; or &#39;POTS&#39; or &#39;VoIP&#39; or
    /// &#39;Cardioid Microphone&#39;.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;7&quot;</span>)]
    </span><span class="kw">pub </span>recording_device_name: ::prost::alloc::string::String,
    <span class="doccomment">/// Mime type of the original audio file.  For example `audio/m4a`,
    /// `audio/x-alaw-basic`, `audio/mp3`, `audio/3gpp`.
    /// A list of possible audio mime types is maintained at
    /// http://www.iana.org/assignments/media-types/media-types.xhtml#audio
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;8&quot;</span>)]
    </span><span class="kw">pub </span>original_mime_type: ::prost::alloc::string::String,
    <span class="doccomment">/// Description of the content. Eg. &quot;Recordings of federal supreme court
    /// hearings from 2012&quot;.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;10&quot;</span>)]
    </span><span class="kw">pub </span>audio_topic: ::prost::alloc::string::String,
}
<span class="doccomment">/// Nested message and enum types in `RecognitionMetadata`.
</span><span class="kw">pub mod </span>recognition_metadata {
    <span class="doccomment">/// Use case categories that the audio recognition request can be described
    /// by.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>InteractionType {
        <span class="doccomment">/// Use case is either unknown or is something other than one of the other
        /// values below.
        </span>Unspecified = <span class="number">0</span>,
        <span class="doccomment">/// Multiple people in a conversation or discussion. For example in a
        /// meeting with two or more people actively participating. Typically
        /// all the primary people speaking would be in the same room (if not,
        /// see PHONE_CALL)
        </span>Discussion = <span class="number">1</span>,
        <span class="doccomment">/// One or more persons lecturing or presenting to others, mostly
        /// uninterrupted.
        </span>Presentation = <span class="number">2</span>,
        <span class="doccomment">/// A phone-call or video-conference in which two or more people, who are
        /// not in the same room, are actively participating.
        </span>PhoneCall = <span class="number">3</span>,
        <span class="doccomment">/// A recorded message intended for another person to listen to.
        </span>Voicemail = <span class="number">4</span>,
        <span class="doccomment">/// Professionally produced audio (eg. TV Show, Podcast).
        </span>ProfessionallyProduced = <span class="number">5</span>,
        <span class="doccomment">/// Transcribe spoken questions and queries into text.
        </span>VoiceSearch = <span class="number">6</span>,
        <span class="doccomment">/// Transcribe voice commands, such as for controlling a device.
        </span>VoiceCommand = <span class="number">7</span>,
        <span class="doccomment">/// Transcribe speech to text to create a written document, such as a
        /// text-message, email or report.
        </span>Dictation = <span class="number">8</span>,
    }
    <span class="doccomment">/// Enumerates the types of capture settings describing an audio file.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>MicrophoneDistance {
        <span class="doccomment">/// Audio type is not known.
        </span>Unspecified = <span class="number">0</span>,
        <span class="doccomment">/// The audio was captured from a closely placed microphone. Eg. phone,
        /// dictaphone, or handheld microphone. Generally if there speaker is within
        /// 1 meter of the microphone.
        </span>Nearfield = <span class="number">1</span>,
        <span class="doccomment">/// The speaker if within 3 meters of the microphone.
        </span>Midfield = <span class="number">2</span>,
        <span class="doccomment">/// The speaker is more than 3 meters away from the microphone.
        </span>Farfield = <span class="number">3</span>,
    }
    <span class="doccomment">/// The original media the speech was recorded on.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>OriginalMediaType {
        <span class="doccomment">/// Unknown original media type.
        </span>Unspecified = <span class="number">0</span>,
        <span class="doccomment">/// The speech data is an audio recording.
        </span>Audio = <span class="number">1</span>,
        <span class="doccomment">/// The speech data originally recorded on a video.
        </span>Video = <span class="number">2</span>,
    }
    <span class="doccomment">/// The type of device the speech was recorded with.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>RecordingDeviceType {
        <span class="doccomment">/// The recording device is unknown.
        </span>Unspecified = <span class="number">0</span>,
        <span class="doccomment">/// Speech was recorded on a smartphone.
        </span>Smartphone = <span class="number">1</span>,
        <span class="doccomment">/// Speech was recorded using a personal computer or tablet.
        </span>Pc = <span class="number">2</span>,
        <span class="doccomment">/// Speech was recorded over a phone line.
        </span>PhoneLine = <span class="number">3</span>,
        <span class="doccomment">/// Speech was recorded in a vehicle.
        </span>Vehicle = <span class="number">4</span>,
        <span class="doccomment">/// Speech was recorded outdoors.
        </span>OtherOutdoorDevice = <span class="number">5</span>,
        <span class="doccomment">/// Speech was recorded indoors.
        </span>OtherIndoorDevice = <span class="number">6</span>,
    }
}
<span class="doccomment">/// Provides &quot;hints&quot; to the speech recognizer to favor specific words and phrases
/// in the results.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>SpeechContext {
    <span class="doccomment">/// A list of strings containing words and phrases &quot;hints&quot; so that
    /// the speech recognition is more likely to recognize them. This can be used
    /// to improve the accuracy for specific words and phrases, for example, if
    /// specific commands are typically spoken by the user. This can also be used
    /// to add additional words to the vocabulary of the recognizer. See
    /// [usage limits](https://cloud.google.com/speech-to-text/quotas#content).
    ///
    /// List items can also be set to classes for groups of words that represent
    /// common concepts that occur in natural language. For example, rather than
    /// providing phrase hints for every month of the year, using the $MONTH class
    /// improves the likelihood of correctly transcribing audio that includes
    /// months.
    </span><span class="attribute">#[prost(string, repeated, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>phrases: ::prost::alloc::vec::Vec&lt;::prost::alloc::string::String&gt;,
}
<span class="doccomment">/// Contains audio data in the encoding specified in the `RecognitionConfig`.
/// Either `content` or `uri` must be supplied. Supplying both or neither
/// returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See
/// [content limits](https://cloud.google.com/speech-to-text/quotas#content).
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>RecognitionAudio {
    <span class="doccomment">/// The audio source, which is either inline content or a Google Cloud
    /// Storage uri.
    </span><span class="attribute">#[prost(oneof = <span class="string">&quot;recognition_audio::AudioSource&quot;</span>, tags = <span class="string">&quot;1, 2&quot;</span>)]
    </span><span class="kw">pub </span>audio_source: ::core::option::Option&lt;recognition_audio::AudioSource&gt;,
}
<span class="doccomment">/// Nested message and enum types in `RecognitionAudio`.
</span><span class="kw">pub mod </span>recognition_audio {
    <span class="doccomment">/// The audio source, which is either inline content or a Google Cloud
    /// Storage uri.
    </span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Oneof)]
    </span><span class="kw">pub enum </span>AudioSource {
        <span class="doccomment">/// The audio data bytes encoded as specified in
        /// `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
        /// pure binary representation, whereas JSON representations use base64.
        </span><span class="attribute">#[prost(bytes, tag = <span class="string">&quot;1&quot;</span>)]
        </span>Content(::prost::alloc::vec::Vec&lt;u8&gt;),
        <span class="doccomment">/// URI that points to a file that contains audio data bytes as specified in
        /// `RecognitionConfig`. The file must not be compressed (for example, gzip).
        /// Currently, only Google Cloud Storage URIs are
        /// supported, which must be specified in the following format:
        /// `gs://bucket_name/object_name` (other URI formats return
        /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
        /// [Request URIs](https://cloud.google.com/storage/docs/reference-uris).
        </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;2&quot;</span>)]
        </span>Uri(::prost::alloc::string::String),
    }
}
<span class="doccomment">/// The only message returned to the client by the `Recognize` method. It
/// contains the result as zero or more sequential `SpeechRecognitionResult`
/// messages.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>RecognizeResponse {
    <span class="doccomment">/// Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>results: ::prost::alloc::vec::Vec&lt;SpeechRecognitionResult&gt;,
}
<span class="doccomment">/// The only message returned to the client by the `LongRunningRecognize` method.
/// It contains the result as zero or more sequential `SpeechRecognitionResult`
/// messages. It is included in the `result.response` field of the `Operation`
/// returned by the `GetOperation` call of the `google::longrunning::Operations`
/// service.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>LongRunningRecognizeResponse {
    <span class="doccomment">/// Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>results: ::prost::alloc::vec::Vec&lt;SpeechRecognitionResult&gt;,
}
<span class="doccomment">/// Describes the progress of a long-running `LongRunningRecognize` call. It is
/// included in the `metadata` field of the `Operation` returned by the
/// `GetOperation` call of the `google::longrunning::Operations` service.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>LongRunningRecognizeMetadata {
    <span class="doccomment">/// Approximate percentage of audio processed thus far. Guaranteed to be 100
    /// when the audio is fully processed and the results are available.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>progress_percent: i32,
    <span class="doccomment">/// Time when the request was received.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>start_time: ::core::option::Option&lt;::prost_types::Timestamp&gt;,
    <span class="doccomment">/// Time of the most recent processing update.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>last_update_time: ::core::option::Option&lt;::prost_types::Timestamp&gt;,
}
<span class="doccomment">/// `StreamingRecognizeResponse` is the only message returned to the client by
/// `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
/// messages are streamed back to the client. If there is no recognizable
/// audio, and `single_utterance` is set to false, then no messages are streamed
/// back to the client.
///
/// Here&#39;s an example of a series of ten `StreamingRecognizeResponse`s that might
/// be returned while processing audio:
///
/// 1. results { alternatives { transcript: &quot;tube&quot; } stability: 0.01 }
///
/// 2. results { alternatives { transcript: &quot;to be a&quot; } stability: 0.01 }
///
/// 3. results { alternatives { transcript: &quot;to be&quot; } stability: 0.9 }
///    results { alternatives { transcript: &quot; or not to be&quot; } stability: 0.01 }
///
/// 4. results { alternatives { transcript: &quot;to be or not to be&quot;
///                             confidence: 0.92 }
///              alternatives { transcript: &quot;to bee or not to bee&quot; }
///              is_final: true }
///
/// 5. results { alternatives { transcript: &quot; that&#39;s&quot; } stability: 0.01 }
///
/// 6. results { alternatives { transcript: &quot; that is&quot; } stability: 0.9 }
///    results { alternatives { transcript: &quot; the question&quot; } stability: 0.01 }
///
/// 7. results { alternatives { transcript: &quot; that is the question&quot;
///                             confidence: 0.98 }
///              alternatives { transcript: &quot; that was the question&quot; }
///              is_final: true }
///
/// Notes:
///
/// - Only two of the above responses #4 and #7 contain final results; they are
///   indicated by `is_final: true`. Concatenating these together generates the
///   full transcript: &quot;to be or not to be that is the question&quot;.
///
/// - The others contain interim `results`. #3 and #6 contain two interim
///   `results`: the first portion has a high stability and is less likely to
///   change; the second portion has a low stability and is very likely to
///   change. A UI designer might choose to show only high stability `results`.
///
/// - The specific `stability` and `confidence` values shown above are only for
///   illustrative purposes. Actual values may vary.
///
/// - In each response, only one of these fields will be set:
///     `error`,
///     `speech_event_type`, or
///     one or more (repeated) `results`.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>StreamingRecognizeResponse {
    <span class="doccomment">/// If set, returns a [google.rpc.Status][google.rpc.Status] message that
    /// specifies the error for the operation.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>error: ::core::option::Option&lt;<span class="kw">super</span>::<span class="kw">super</span>::<span class="kw">super</span>::rpc::Status&gt;,
    <span class="doccomment">/// This repeated list contains zero or more results that
    /// correspond to consecutive portions of the audio currently being processed.
    /// It contains zero or one `is_final=true` result (the newly settled portion),
    /// followed by zero or more `is_final=false` results (the interim results).
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>results: ::prost::alloc::vec::Vec&lt;StreamingRecognitionResult&gt;,
    <span class="doccomment">/// Indicates the type of speech event.
    </span><span class="attribute">#[prost(
        enumeration = <span class="string">&quot;streaming_recognize_response::SpeechEventType&quot;</span>,
        tag = <span class="string">&quot;4&quot;
    </span>)]
    </span><span class="kw">pub </span>speech_event_type: i32,
}
<span class="doccomment">/// Nested message and enum types in `StreamingRecognizeResponse`.
</span><span class="kw">pub mod </span>streaming_recognize_response {
    <span class="doccomment">/// Indicates the type of speech event.
    </span><span class="attribute">#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    </span><span class="kw">pub enum </span>SpeechEventType {
        <span class="doccomment">/// No speech event specified.
        </span>SpeechEventUnspecified = <span class="number">0</span>,
        <span class="doccomment">/// This event indicates that the server has detected the end of the user&#39;s
        /// speech utterance and expects no additional speech. Therefore, the server
        /// will not process additional audio (although it may subsequently return
        /// additional results). The client should stop sending additional audio
        /// data, half-close the gRPC connection, and wait for any additional results
        /// until the server closes the gRPC connection. This event is only sent if
        /// `single_utterance` was set to `true`, and is not used otherwise.
        </span>EndOfSingleUtterance = <span class="number">1</span>,
    }
}
<span class="doccomment">/// A streaming speech recognition result corresponding to a portion of the audio
/// that is currently being processed.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>StreamingRecognitionResult {
    <span class="doccomment">/// May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// These alternatives are ordered in terms of accuracy, with the top (first)
    /// alternative being the most probable, as ranked by the recognizer.
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>alternatives: ::prost::alloc::vec::Vec&lt;SpeechRecognitionAlternative&gt;,
    <span class="doccomment">/// If `false`, this `StreamingRecognitionResult` represents an
    /// interim result that may change. If `true`, this is the final time the
    /// speech service will return this particular `StreamingRecognitionResult`,
    /// the recognizer will not return any further hypotheses for this portion of
    /// the transcript and corresponding audio.
    </span><span class="attribute">#[prost(bool, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>is_final: bool,
    <span class="doccomment">/// An estimate of the likelihood that the recognizer will not
    /// change its guess about this interim result. Values range from 0.0
    /// (completely unstable) to 1.0 (completely stable).
    /// This field is only provided for interim results (`is_final=false`).
    /// The default of 0.0 is a sentinel value indicating `stability` was not set.
    </span><span class="attribute">#[prost(float, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>stability: f32,
    <span class="doccomment">/// Time offset of the end of this result relative to the
    /// beginning of the audio.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;4&quot;</span>)]
    </span><span class="kw">pub </span>result_end_time: ::core::option::Option&lt;::prost_types::Duration&gt;,
    <span class="doccomment">/// For multi-channel audio, this is the channel number corresponding to the
    /// recognized result for the audio from that channel.
    /// For audio_channel_count = N, its output values can range from &#39;1&#39; to &#39;N&#39;.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;5&quot;</span>)]
    </span><span class="kw">pub </span>channel_tag: i32,
    <span class="doccomment">/// The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag of
    /// the language in this result. This language code was detected to have the
    /// most likelihood of being spoken in the audio.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;6&quot;</span>)]
    </span><span class="kw">pub </span>language_code: ::prost::alloc::string::String,
}
<span class="doccomment">/// A speech recognition result corresponding to a portion of the audio.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>SpeechRecognitionResult {
    <span class="doccomment">/// May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// These alternatives are ordered in terms of accuracy, with the top (first)
    /// alternative being the most probable, as ranked by the recognizer.
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>alternatives: ::prost::alloc::vec::Vec&lt;SpeechRecognitionAlternative&gt;,
    <span class="doccomment">/// For multi-channel audio, this is the channel number corresponding to the
    /// recognized result for the audio from that channel.
    /// For audio_channel_count = N, its output values can range from &#39;1&#39; to &#39;N&#39;.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>channel_tag: i32,
}
<span class="doccomment">/// Alternative hypotheses (a.k.a. n-best list).
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>SpeechRecognitionAlternative {
    <span class="doccomment">/// Transcript text representing the words that the user spoke.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>transcript: ::prost::alloc::string::String,
    <span class="doccomment">/// The confidence estimate between 0.0 and 1.0. A higher number
    /// indicates an estimated greater likelihood that the recognized words are
    /// correct. This field is set only for the top alternative of a non-streaming
    /// result or, of a streaming result where `is_final=true`.
    /// This field is not guaranteed to be accurate and users should not rely on it
    /// to be always provided.
    /// The default of 0.0 is a sentinel value indicating `confidence` was not set.
    </span><span class="attribute">#[prost(float, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>confidence: f32,
    <span class="doccomment">/// A list of word-specific information for each recognized word.
    /// Note: When `enable_speaker_diarization` is true, you will see all the words
    /// from the beginning of the audio.
    </span><span class="attribute">#[prost(message, repeated, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>words: ::prost::alloc::vec::Vec&lt;WordInfo&gt;,
}
<span class="doccomment">/// Word-specific information for recognized words.
</span><span class="attribute">#[derive(Clone, PartialEq, ::prost::Message)]
</span><span class="kw">pub struct </span>WordInfo {
    <span class="doccomment">/// Time offset relative to the beginning of the audio,
    /// and corresponding to the start of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;1&quot;</span>)]
    </span><span class="kw">pub </span>start_time: ::core::option::Option&lt;::prost_types::Duration&gt;,
    <span class="doccomment">/// Time offset relative to the beginning of the audio,
    /// and corresponding to the end of the spoken word.
    /// This field is only set if `enable_word_time_offsets=true` and only
    /// in the top hypothesis.
    /// This is an experimental feature and the accuracy of the time offset can
    /// vary.
    </span><span class="attribute">#[prost(message, optional, tag = <span class="string">&quot;2&quot;</span>)]
    </span><span class="kw">pub </span>end_time: ::core::option::Option&lt;::prost_types::Duration&gt;,
    <span class="doccomment">/// The word corresponding to this set of information.
    </span><span class="attribute">#[prost(string, tag = <span class="string">&quot;3&quot;</span>)]
    </span><span class="kw">pub </span>word: ::prost::alloc::string::String,
    <span class="doccomment">/// A distinct integer value is assigned for every speaker within
    /// the audio. This field specifies which one of those speakers was detected to
    /// have spoken this word. Value ranges from &#39;1&#39; to diarization_speaker_count.
    /// speaker_tag is set if enable_speaker_diarization = &#39;true&#39; and only in the
    /// top alternative.
    </span><span class="attribute">#[prost(int32, tag = <span class="string">&quot;5&quot;</span>)]
    </span><span class="kw">pub </span>speaker_tag: i32,
}
<span class="attribute">#[doc = <span class="string">r&quot; Generated client implementations.&quot;</span>]
</span><span class="kw">pub mod </span>speech_client {
    <span class="attribute">#![allow(unused_variables, dead_code, missing_docs)]
    </span><span class="kw">use </span>tonic::codegen::<span class="kw-2">*</span>;
    <span class="attribute">#[doc = <span class="string">&quot; Service that implements Google Cloud Speech API.&quot;</span>]
    </span><span class="kw">pub struct </span>SpeechClient&lt;T&gt; {
        inner: tonic::client::Grpc&lt;T&gt;,
    }
    <span class="kw">impl </span>SpeechClient&lt;tonic::transport::Channel&gt; {
        <span class="attribute">#[doc = <span class="string">r&quot; Attempt to create a new client by connecting to a given endpoint.&quot;</span>]
        </span><span class="kw">pub async fn </span>connect&lt;D&gt;(dst: D) -&gt; <span class="prelude-ty">Result</span>&lt;<span class="self">Self</span>, tonic::transport::Error&gt;
        <span class="kw">where
            </span>D: std::convert::TryInto&lt;tonic::transport::Endpoint&gt;,
            D::Error: Into&lt;StdError&gt;,
        {
            <span class="kw">let </span>conn = tonic::transport::Endpoint::new(dst)<span class="question-mark">?</span>.connect().<span class="kw">await</span><span class="question-mark">?</span>;
            <span class="prelude-val">Ok</span>(<span class="self">Self</span>::new(conn))
        }
    }
    <span class="kw">impl</span>&lt;T&gt; SpeechClient&lt;T&gt;
    <span class="kw">where
        </span>T: tonic::client::GrpcService&lt;tonic::body::BoxBody&gt;,
        T::ResponseBody: Body + HttpBody + Send + <span class="lifetime">&#39;static</span>,
        T::Error: Into&lt;StdError&gt;,
        &lt;T::ResponseBody <span class="kw">as </span>HttpBody&gt;::Error: Into&lt;StdError&gt; + Send,
    {
        <span class="kw">pub fn </span>new(inner: T) -&gt; <span class="self">Self </span>{
            <span class="kw">let </span>inner = tonic::client::Grpc::new(inner);
            <span class="self">Self </span>{ inner }
        }
        <span class="kw">pub fn </span>with_interceptor(inner: T, interceptor: <span class="kw">impl </span>Into&lt;tonic::Interceptor&gt;) -&gt; <span class="self">Self </span>{
            <span class="kw">let </span>inner = tonic::client::Grpc::with_interceptor(inner, interceptor);
            <span class="self">Self </span>{ inner }
        }
        <span class="attribute">#[doc = <span class="string">&quot; Performs synchronous speech recognition: receive results after all audio&quot;</span>]
        #[doc = <span class="string">&quot; has been sent and processed.&quot;</span>]
        </span><span class="kw">pub async fn </span>recognize(
            <span class="kw-2">&amp;mut </span><span class="self">self</span>,
            request: <span class="kw">impl </span>tonic::IntoRequest&lt;<span class="kw">super</span>::RecognizeRequest&gt;,
        ) -&gt; <span class="prelude-ty">Result</span>&lt;tonic::Response&lt;<span class="kw">super</span>::RecognizeResponse&gt;, tonic::Status&gt; {
            <span class="self">self</span>.inner.ready().<span class="kw">await</span>.map_err(|e| {
                tonic::Status::new(
                    tonic::Code::Unknown,
                    <span class="macro">format!</span>(<span class="string">&quot;Service was not ready: {}&quot;</span>, e.into()),
                )
            })<span class="question-mark">?</span>;
            <span class="kw">let </span>codec = tonic::codec::ProstCodec::default();
            <span class="kw">let </span>path =
                http::uri::PathAndQuery::from_static(<span class="string">&quot;/google.cloud.speech.v1.Speech/Recognize&quot;</span>);
            <span class="self">self</span>.inner.unary(request.into_request(), path, codec).<span class="kw">await
        </span>}
        <span class="attribute">#[doc = <span class="string">&quot; Performs asynchronous speech recognition: receive results via the&quot;</span>]
        #[doc = <span class="string">&quot; google.longrunning.Operations interface. Returns either an&quot;</span>]
        #[doc = <span class="string">&quot; `Operation.error` or an `Operation.response` which contains&quot;</span>]
        #[doc = <span class="string">&quot; a `LongRunningRecognizeResponse` message.&quot;</span>]
        #[doc = <span class="string">&quot; For more information on asynchronous speech recognition, see the&quot;</span>]
        #[doc = <span class="string">&quot; [how-to](https://cloud.google.com/speech-to-text/docs/async-recognize).&quot;</span>]
        </span><span class="kw">pub async fn </span>long_running_recognize(
            <span class="kw-2">&amp;mut </span><span class="self">self</span>,
            request: <span class="kw">impl </span>tonic::IntoRequest&lt;<span class="kw">super</span>::LongRunningRecognizeRequest&gt;,
        ) -&gt; <span class="prelude-ty">Result</span>&lt;
            tonic::Response&lt;<span class="kw">super</span>::<span class="kw">super</span>::<span class="kw">super</span>::<span class="kw">super</span>::longrunning::Operation&gt;,
            tonic::Status,
        &gt; {
            <span class="self">self</span>.inner.ready().<span class="kw">await</span>.map_err(|e| {
                tonic::Status::new(
                    tonic::Code::Unknown,
                    <span class="macro">format!</span>(<span class="string">&quot;Service was not ready: {}&quot;</span>, e.into()),
                )
            })<span class="question-mark">?</span>;
            <span class="kw">let </span>codec = tonic::codec::ProstCodec::default();
            <span class="kw">let </span>path = http::uri::PathAndQuery::from_static(
                <span class="string">&quot;/google.cloud.speech.v1.Speech/LongRunningRecognize&quot;</span>,
            );
            <span class="self">self</span>.inner.unary(request.into_request(), path, codec).<span class="kw">await
        </span>}
        <span class="attribute">#[doc = <span class="string">&quot; Performs bidirectional streaming speech recognition: receive results while&quot;</span>]
        #[doc = <span class="string">&quot; sending audio. This method is only available via the gRPC API (not REST).&quot;</span>]
        </span><span class="kw">pub async fn </span>streaming_recognize(
            <span class="kw-2">&amp;mut </span><span class="self">self</span>,
            request: <span class="kw">impl </span>tonic::IntoStreamingRequest&lt;Message = <span class="kw">super</span>::StreamingRecognizeRequest&gt;,
        ) -&gt; <span class="prelude-ty">Result</span>&lt;
            tonic::Response&lt;tonic::codec::Streaming&lt;<span class="kw">super</span>::StreamingRecognizeResponse&gt;&gt;,
            tonic::Status,
        &gt; {
            <span class="self">self</span>.inner.ready().<span class="kw">await</span>.map_err(|e| {
                tonic::Status::new(
                    tonic::Code::Unknown,
                    <span class="macro">format!</span>(<span class="string">&quot;Service was not ready: {}&quot;</span>, e.into()),
                )
            })<span class="question-mark">?</span>;
            <span class="kw">let </span>codec = tonic::codec::ProstCodec::default();
            <span class="kw">let </span>path = http::uri::PathAndQuery::from_static(
                <span class="string">&quot;/google.cloud.speech.v1.Speech/StreamingRecognize&quot;</span>,
            );
            <span class="self">self</span>.inner
                .streaming(request.into_streaming_request(), path, codec)
                .<span class="kw">await
        </span>}
    }
    <span class="kw">impl</span>&lt;T: Clone&gt; Clone <span class="kw">for </span>SpeechClient&lt;T&gt; {
        <span class="kw">fn </span>clone(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="self">Self </span>{
            <span class="self">Self </span>{
                inner: <span class="self">self</span>.inner.clone(),
            }
        }
    }
    <span class="kw">impl</span>&lt;T&gt; std::fmt::Debug <span class="kw">for </span>SpeechClient&lt;T&gt; {
        <span class="kw">fn </span>fmt(<span class="kw-2">&amp;</span><span class="self">self</span>, f: <span class="kw-2">&amp;mut </span>std::fmt::Formatter&lt;<span class="lifetime">&#39;_</span>&gt;) -&gt; std::fmt::Result {
            <span class="macro">write!</span>(f, <span class="string">&quot;SpeechClient {{ ... }}&quot;</span>)
        }
    }
}
</code></pre></div>
</section></div></main><div id="rustdoc-vars" data-root-path="../../../../../" data-current-crate="google_cognitive_apis" data-themes="ayu,dark,light" data-resource-suffix="" data-rustdoc-version="1.65.0-nightly (9243168fa 2022-08-31)" ></div></body></html>